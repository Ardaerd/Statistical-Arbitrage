{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:33:41.644867Z",
     "start_time": "2024-01-17T12:33:39.368720Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from hyperopt import hp\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from functools import partial\n",
    "from ray.experimental.tqdm_ray import tqdm\n",
    "from ray.util.accelerators import NVIDIA_TESLA_V100\n",
    "\n",
    "import torch\n",
    "from ray import train, tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import train\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import talib\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "CUDA available: False\n",
      "CUDA version: None\n",
      "cuDNN version: None\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"gpu\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "print('CUDA version:', torch.version.cuda)\n",
    "print('cuDNN version:', torch.backends.cudnn.version())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:33:41.659289Z",
     "start_time": "2024-01-17T12:33:41.602266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def add_technical_indicators(spread, timeperiod=22):\n",
    "\n",
    "    # MACD\n",
    "    macd, macdsignal, macdhist = talib.MACD(spread, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "    rsi = talib.RSI(spread, timeperiod=14)\n",
    "\n",
    "    # CMO\n",
    "    cmo = talib.CMO(spread, timeperiod=timeperiod)\n",
    "\n",
    "    # MOM\n",
    "    mom = talib.MOM(spread, timeperiod=timeperiod)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    upperband, middleband, lowerband = talib.BBANDS(spread, timeperiod=timeperiod, nbdevup=2, nbdevdn=2, matype=0)\n",
    "\n",
    "    # SMA\n",
    "    sma = talib.SMA(spread, timeperiod=timeperiod)\n",
    "\n",
    "    # Combine all indicators into a DataFrame\n",
    "    indicators = pd.DataFrame({\n",
    "        'MACD': macd,\n",
    "        'MACD_signal': macdsignal,\n",
    "        'MACD_hist': macdhist,\n",
    "        'RSI': rsi,\n",
    "        'CMO': cmo,\n",
    "        'MOM': mom,\n",
    "        'Upper_BB': upperband,\n",
    "        'Middle_BB': middleband,\n",
    "        'Lower_BB': lowerband,\n",
    "        'SMA': sma\n",
    "    })\n",
    "    return indicators\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:33:41.665266Z",
     "start_time": "2024-01-17T12:33:41.618497Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{('SWKS',\n  'QRVO'):           MACD  MACD_signal  MACD_hist        RSI        CMO       MOM  \\\n 33    2.030602     1.107445   0.923157  73.712986  37.256446  7.412430   \n 34    2.264091     1.338774   0.925317  74.970416  39.211667  8.581909   \n 35    2.313134     1.533646   0.779488  68.137934  30.893807  7.610367   \n 36    1.931359     1.613189   0.318171  50.189722   6.584774  2.025627   \n 37    1.472331     1.585017  -0.112686  45.654763  -0.213434  0.463966   \n ...        ...          ...        ...        ...        ...       ...   \n 1001 -0.036478     0.001545  -0.038023  47.853326  -3.562012 -0.310005   \n 1002 -0.068166    -0.012397  -0.055769  47.236833  -4.324748 -0.789993   \n 1003 -0.118541    -0.033626  -0.084915  45.349182  -6.645434 -1.709999   \n 1004 -0.161444    -0.059189  -0.102255  44.997068  -7.074799 -1.520004   \n 1005 -0.187634    -0.084878  -0.102756  45.528411  -6.476312 -1.459999   \n \n       Upper_BB  Middle_BB  Lower_BB       SMA    Spread  \n 33    7.503425   1.239307 -5.024811  1.239307  7.912239  \n 34    8.574625   1.629394 -5.315838  1.629394  8.608337  \n 35    9.241053   1.975320 -5.290414  1.975320  7.253357  \n 36    9.296648   2.067394 -5.161861  2.067394  2.316322  \n 37    9.297611   2.088483 -5.120646  2.088483  0.587555  \n ...        ...        ...       ...       ...       ...  \n 1001  2.363795   0.846818 -0.670159  0.846818  0.239998  \n 1002  2.356390   0.810909 -0.734571  0.810909  0.130005  \n 1003  2.302032   0.733182 -0.835668  0.733182 -0.199997  \n 1004  2.267550   0.664091 -0.939368  0.664091 -0.260002  \n 1005  2.216167   0.597727 -1.020713  0.597727 -0.190002  \n \n [973 rows x 11 columns],\n ('AMAT',\n  'NXPI'):           MACD  MACD_signal  MACD_hist        RSI        CMO        MOM  \\\n 33   -0.059851    -0.691579   0.631728  53.642166  -1.092871   2.716030   \n 34    0.224086    -0.508446   0.732532  59.316643   7.663180   4.466225   \n 35    0.681371    -0.270482   0.951854  66.059860  18.771890   7.415562   \n 36    1.101718     0.003958   1.097760  67.753320  21.676187   9.949696   \n 37    1.592529     0.321672   1.270857  71.561272  28.362878  12.890224   \n ...        ...          ...        ...        ...        ...        ...   \n 1001 -4.939395    -4.862570  -0.076825  37.768258 -20.777198 -16.311539   \n 1002 -4.766945    -4.843445   0.076500  36.757995 -22.083161 -18.487579   \n 1003 -4.595061    -4.793769   0.198707  36.457929 -22.465730 -19.030075   \n 1004 -4.412816    -4.717578   0.304762  36.370708 -22.574369 -20.017960   \n 1005 -4.192618    -4.612586   0.419968  37.286180 -21.563332 -16.559647   \n \n        Upper_BB  Middle_BB   Lower_BB        SMA     Spread  \n 33   -60.831849 -64.473088 -68.114327 -64.473088 -62.253860  \n 34   -60.235507 -64.270078 -68.304649 -64.270078 -60.279488  \n 35   -58.972140 -63.933007 -68.893874 -63.933007 -57.303745  \n 36   -57.740938 -63.480748 -69.220558 -63.480748 -56.428257  \n 37   -56.213109 -62.894829 -69.576549 -62.894829 -54.246605  \n ...         ...        ...        ...        ...        ...  \n 1001 -45.738829 -60.551437 -75.364045 -60.551437 -66.899994  \n 1002 -47.168517 -61.391781 -75.615046 -61.391781 -67.669998  \n 1003 -48.898946 -62.256785 -75.614623 -62.256785 -67.889999  \n 1004 -51.179004 -63.166692 -75.154380 -63.166692 -67.950012  \n 1005 -53.041169 -63.919403 -74.797637 -63.919403 -67.609985  \n \n [973 rows x 11 columns],\n ('ANET',\n  'PANW'):           MACD  MACD_signal  MACD_hist        RSI        CMO        MOM  \\\n 33    0.502364     1.591379  -1.089015  43.871329   1.083424  -0.754166   \n 34    0.418853     1.356874  -0.938021  48.224607   6.008026   0.631668   \n 35    0.305774     1.146654  -0.840880  45.782558   2.590967  -0.109169   \n 36    1.132402     1.143804  -0.011401  74.997351  43.483223   9.962498   \n 37    1.906543     1.296351   0.610191  77.020723  47.018781   9.045834   \n ...        ...          ...        ...        ...        ...        ...   \n 1001 -3.222331    -5.413837   2.191505  53.692244   1.532194 -11.240005   \n 1002 -2.591950    -4.849459   2.257509  51.052176  -1.621691 -17.839996   \n 1003 -1.787725    -4.237113   2.449387  53.639392   1.747941 -12.080017   \n 1004 -1.044725    -3.598635   2.553910  54.493049   2.859978  -8.189987   \n 1005 -0.511325    -2.981173   2.469848  53.794146   2.067058   1.209976   \n \n        Upper_BB  Middle_BB   Lower_BB        SMA     Spread  \n 33   -19.530350 -23.535568 -27.540786 -23.535568 -25.976669  \n 34   -19.557357 -23.506856 -27.456355 -23.506856 -25.134998  \n 35   -19.551736 -23.511818 -27.471900 -23.511818 -25.672501  \n 36   -17.517276 -23.058977 -28.600679 -23.058977 -14.155834  \n 37   -15.563263 -22.647803 -29.732343 -22.647803 -12.408333  \n ...         ...        ...        ...        ...        ...  \n 1001 -48.639366 -68.668178 -88.696989 -68.668178 -59.949997  \n 1002 -51.992895 -69.479086 -86.965278 -69.479086 -63.290009  \n 1003 -54.686101 -70.028178 -85.370255 -70.028178 -59.770004  \n 1004 -56.666406 -70.400450 -84.134494 -70.400450 -58.609985  \n 1005 -56.445848 -70.345451 -84.245055 -70.345451 -59.370010  \n \n [973 rows x 11 columns],\n ('CDNS',\n  'PANW'):           MACD  MACD_signal  MACD_hist        RSI        CMO        MOM  \\\n 33    0.859909     0.718619   0.141290  49.077470   1.242602   0.883331   \n 34    0.701170     0.715129  -0.013959  48.402672   0.241905   0.206673   \n 35    0.453142     0.662732  -0.209590  43.564492  -6.982157  -1.276672   \n 36    1.092590     0.748703   0.343886  68.307816  30.871128   9.009995   \n 37    1.811672     0.961297   0.850375  71.947638  37.261821  12.073330   \n ...        ...          ...        ...        ...        ...        ...   \n 1001 -6.584202    -8.208593   1.624391  48.532260  -7.727759 -28.750000   \n 1002 -5.941041    -7.755083   1.814042  45.605641 -11.279096 -33.070007   \n 1003 -5.130117    -7.230090   2.099972  48.497272  -7.530671 -27.389984   \n 1004 -4.394835    -6.663039   2.268204  49.003311  -6.876952 -24.799988   \n 1005 -3.782238    -6.086878   2.304641  48.834363  -7.070463 -15.400024   \n \n        Upper_BB  Middle_BB   Lower_BB        SMA     Spread  \n 33    -3.006032  -5.831818  -8.657604  -5.831818  -6.076668  \n 34    -3.003911  -5.822424  -8.640937  -5.822424  -6.269997  \n 35    -2.962383  -5.880454  -8.798526  -5.880454  -7.720001  \n 36    -0.832633  -5.470909 -10.109185  -5.470909   2.796661  \n 37     1.619382  -4.922121 -11.463625  -4.922121   5.686665  \n ...         ...        ...        ...        ...        ...  \n 1001   3.233448 -23.671815 -50.577079 -23.671815 -22.389984  \n 1002  -1.887058 -25.174998 -48.462937 -25.174998 -25.860016  \n 1003  -7.012048 -26.419997 -45.827946 -26.419997 -22.859985  \n 1004 -12.615223 -27.547269 -42.479315 -27.547269 -22.339996  \n 1005 -16.013008 -28.247270 -40.481532 -28.247270 -22.510010  \n \n [973 rows x 11 columns]}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"Technology_Firm_Stock_Price.csv\")\n",
    "data = data.sort_values(by=\"Date\")\n",
    "selected_pairs = [('SWKS', 'QRVO'), ('AMAT', 'NXPI'), ('ANET', 'PANW'), ('CDNS', 'PANW')]\n",
    "spreads_with_indicators = {}\n",
    "for stock1, stock2 in selected_pairs:\n",
    "    spread = data[stock1] - data[stock2]\n",
    "    indicators = add_technical_indicators(spread)\n",
    "    indicators['Spread'] = spread\n",
    "    spreads_with_indicators[(stock1, stock2)] = indicators.dropna()  # Drop rows with NaN 22 column (because of our timeperiod is 22 day for calculate these indicators thus we dropped first 22 column\n",
    "\n",
    "spreads_with_indicators\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:33:41.668529Z",
     "start_time": "2024-01-17T12:33:41.627197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def rolling_window(data):\n",
    "    time_step = 22\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(len(data) - time_step):\n",
    "        X.append(data.iloc[i : (i+time_step)])\n",
    "        y.append(data.iloc[i+time_step])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:33:41.668686Z",
     "start_time": "2024-01-17T12:33:41.627516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        MACD  MACD_signal  MACD_hist        RSI        CMO       MOM  \\\n33  2.030602     1.107445   0.923157  73.712986  37.256446  7.412430   \n34  2.264091     1.338774   0.925317  74.970416  39.211667  8.581909   \n35  2.313134     1.533646   0.779488  68.137934  30.893807  7.610367   \n36  1.931359     1.613189   0.318171  50.189722   6.584774  2.025627   \n37  1.472331     1.585017  -0.112686  45.654763  -0.213434  0.463966   \n\n    Upper_BB  Middle_BB  Lower_BB       SMA    Spread  \n33  7.503425   1.239307 -5.024811  1.239307  7.912239  \n34  8.574625   1.629394 -5.315838  1.629394  8.608337  \n35  9.241053   1.975320 -5.290414  1.975320  7.253357  \n36  9.296648   2.067394 -5.161861  2.067394  2.316322  \n37  9.297611   2.088483 -5.120646  2.088483  0.587555  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MACD</th>\n      <th>MACD_signal</th>\n      <th>MACD_hist</th>\n      <th>RSI</th>\n      <th>CMO</th>\n      <th>MOM</th>\n      <th>Upper_BB</th>\n      <th>Middle_BB</th>\n      <th>Lower_BB</th>\n      <th>SMA</th>\n      <th>Spread</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>2.030602</td>\n      <td>1.107445</td>\n      <td>0.923157</td>\n      <td>73.712986</td>\n      <td>37.256446</td>\n      <td>7.412430</td>\n      <td>7.503425</td>\n      <td>1.239307</td>\n      <td>-5.024811</td>\n      <td>1.239307</td>\n      <td>7.912239</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2.264091</td>\n      <td>1.338774</td>\n      <td>0.925317</td>\n      <td>74.970416</td>\n      <td>39.211667</td>\n      <td>8.581909</td>\n      <td>8.574625</td>\n      <td>1.629394</td>\n      <td>-5.315838</td>\n      <td>1.629394</td>\n      <td>8.608337</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2.313134</td>\n      <td>1.533646</td>\n      <td>0.779488</td>\n      <td>68.137934</td>\n      <td>30.893807</td>\n      <td>7.610367</td>\n      <td>9.241053</td>\n      <td>1.975320</td>\n      <td>-5.290414</td>\n      <td>1.975320</td>\n      <td>7.253357</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>1.931359</td>\n      <td>1.613189</td>\n      <td>0.318171</td>\n      <td>50.189722</td>\n      <td>6.584774</td>\n      <td>2.025627</td>\n      <td>9.296648</td>\n      <td>2.067394</td>\n      <td>-5.161861</td>\n      <td>2.067394</td>\n      <td>2.316322</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1.472331</td>\n      <td>1.585017</td>\n      <td>-0.112686</td>\n      <td>45.654763</td>\n      <td>-0.213434</td>\n      <td>0.463966</td>\n      <td>9.297611</td>\n      <td>2.088483</td>\n      <td>-5.120646</td>\n      <td>2.088483</td>\n      <td>0.587555</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spreads_with_indicators[('SWKS','QRVO')].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:33:42.354244Z",
     "start_time": "2024-01-17T12:33:42.251262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('SWKS', 'QRVO'):          MACD  MACD_signal  MACD_hist       RSI       CMO       MOM  Upper_BB  \\\n",
      "0    0.583049     0.546882   0.560607  0.876858  0.854227  0.524526  0.711123   \n",
      "1    0.599417     0.564780   0.561000  0.896479  0.872540  0.540631  0.738404   \n",
      "2    0.602855     0.579858   0.534516  0.789862  0.794632  0.527252  0.755377   \n",
      "3    0.576091     0.586012   0.450739  0.509789  0.566945  0.450345  0.756793   \n",
      "4    0.543912     0.583832   0.372493  0.439024  0.503271  0.428840  0.756817   \n",
      "..        ...          ...        ...       ...       ...       ...       ...   \n",
      "968  0.438139     0.461318   0.386052  0.473331  0.471907  0.418181  0.580229   \n",
      "969  0.435918     0.460239   0.382830  0.463711  0.464762  0.411571  0.580040   \n",
      "970  0.432386     0.458597   0.377537  0.434255  0.443026  0.398902  0.578656   \n",
      "971  0.429379     0.456619   0.374388  0.428761  0.439005  0.401519  0.577778   \n",
      "972  0.427543     0.454631   0.374297  0.437052  0.444610  0.402345  0.576469   \n",
      "\n",
      "     Middle_BB  Lower_BB       SMA    Spread  \n",
      "0     0.688723  0.711447  0.688723  0.836996  \n",
      "1     0.698263  0.706429  0.698263  0.850531  \n",
      "2     0.706722  0.706867  0.706722  0.824185  \n",
      "3     0.708974  0.709084  0.708974  0.728188  \n",
      "4     0.709489  0.709794  0.709489  0.694573  \n",
      "..         ...       ...       ...       ...  \n",
      "968   0.679125  0.786528  0.679125  0.687815  \n",
      "969   0.678247  0.785417  0.678247  0.685677  \n",
      "970   0.676347  0.783674  0.676347  0.679260  \n",
      "971   0.674657  0.781886  0.674657  0.678093  \n",
      "972   0.673034  0.780484  0.673034  0.679454  \n",
      "\n",
      "[973 rows x 11 columns], ('AMAT', 'NXPI'):          MACD  MACD_signal  MACD_hist       RSI       CMO       MOM  Upper_BB  \\\n",
      "0    0.456083     0.417441   0.653148  0.509072  0.401474  0.503773  0.144272   \n",
      "1    0.476058     0.432261   0.673330  0.591892  0.481852  0.526332  0.157651   \n",
      "2    0.508227     0.451519   0.717242  0.690311  0.583827  0.564347  0.185996   \n",
      "3    0.537798     0.473729   0.746455  0.715028  0.610488  0.597010  0.213619   \n",
      "4    0.572327     0.499440   0.781111  0.770606  0.671870  0.634911  0.247898   \n",
      "..        ...          ...        ...       ...       ...       ...       ...   \n",
      "968  0.112811     0.079895   0.511285  0.277388  0.220777  0.258522  0.482899   \n",
      "969  0.124943     0.081443   0.541983  0.262643  0.208789  0.230475  0.450823   \n",
      "970  0.137035     0.085463   0.566451  0.258263  0.205277  0.223483  0.411999   \n",
      "971  0.149856     0.091629   0.587684  0.256990  0.204280  0.210750  0.360843   \n",
      "972  0.165347     0.100126   0.610750  0.270352  0.213561  0.255325  0.319063   \n",
      "\n",
      "     Middle_BB  Lower_BB       SMA    Spread  \n",
      "0     0.235414  0.379570  0.235414  0.356708  \n",
      "1     0.240444  0.375559  0.240444  0.389018  \n",
      "2     0.248794  0.363140  0.248794  0.437714  \n",
      "3     0.259999  0.356255  0.259999  0.452041  \n",
      "4     0.274514  0.348753  0.274514  0.487743  \n",
      "..         ...       ...       ...       ...  \n",
      "968   0.332570  0.226778  0.332570  0.280677  \n",
      "969   0.311751  0.221488  0.311751  0.268076  \n",
      "970   0.290321  0.221497  0.290321  0.264476  \n",
      "971   0.267779  0.231197  0.267779  0.263494  \n",
      "972   0.249131  0.238715  0.249131  0.269058  \n",
      "\n",
      "[973 rows x 11 columns], ('ANET', 'PANW'):          MACD  MACD_signal  MACD_hist       RSI       CMO       MOM  Upper_BB  \\\n",
      "0    0.520848     0.595079   0.360386  0.415762  0.494445  0.475632  0.690286   \n",
      "1    0.517474     0.584052   0.374697  0.481114  0.538064  0.487696  0.689919   \n",
      "2    0.512905     0.574168   0.383905  0.444453  0.507798  0.481247  0.689996   \n",
      "3    0.546304     0.574034   0.462523  0.883033  0.869993  0.568926  0.717660   \n",
      "4    0.577581     0.581207   0.521438  0.913409  0.901308  0.560946  0.744230   \n",
      "..        ...          ...        ...       ...       ...       ...       ...   \n",
      "968  0.370358     0.265683   0.671317  0.563196  0.498420  0.384347  0.294470   \n",
      "969  0.395827     0.292221   0.677572  0.523562  0.470485  0.326891  0.248870   \n",
      "970  0.428321     0.321015   0.695759  0.562402  0.500331  0.377035  0.212249   \n",
      "971  0.458340     0.351037   0.705666  0.575217  0.510181  0.410899  0.185321   \n",
      "972  0.479892     0.380071   0.697698  0.564725  0.503157  0.492731  0.188320   \n",
      "\n",
      "     Middle_BB  Lower_BB       SMA    Spread  \n",
      "0     0.781967  0.822362  0.781967  0.735048  \n",
      "1     0.782316  0.823183  0.782316  0.743614  \n",
      "2     0.782255  0.823032  0.782255  0.738143  \n",
      "3     0.787763  0.812049  0.787763  0.855353  \n",
      "4     0.792764  0.801037  0.792764  0.873138  \n",
      "..         ...       ...       ...       ...  \n",
      "968   0.233044  0.227297  0.233044  0.389287  \n",
      "969   0.223181  0.244147  0.223181  0.355294  \n",
      "970   0.216503  0.259667  0.216503  0.391119  \n",
      "971   0.211975  0.271691  0.211975  0.402925  \n",
      "972   0.212644  0.270615  0.212644  0.395189  \n",
      "\n",
      "[973 rows x 11 columns], ('CDNS', 'PANW'):          MACD  MACD_signal  MACD_hist       RSI       CMO       MOM  Upper_BB  \\\n",
      "0    0.588916     0.583869   0.587923  0.502565  0.536810  0.538040  0.387356   \n",
      "1    0.580551     0.583656   0.569578  0.491812  0.526430  0.531957  0.387381   \n",
      "2    0.567481     0.580466   0.546461  0.414716  0.451498  0.518623  0.387873   \n",
      "3    0.601177     0.585700   0.611863  0.809000  0.844133  0.611093  0.413137   \n",
      "4    0.639070     0.598645   0.671712  0.867000  0.910421  0.638630  0.442224   \n",
      "..        ...          ...        ...       ...       ...       ...       ...   \n",
      "968  0.196643     0.040309   0.763174  0.493877  0.443765  0.271657  0.461371   \n",
      "969  0.230535     0.067922   0.785585  0.447242  0.406928  0.232823  0.400629   \n",
      "970  0.273267     0.099888   0.819372  0.493320  0.445809  0.283882  0.339834   \n",
      "971  0.312014     0.134414   0.839251  0.501383  0.452590  0.307164  0.273367   \n",
      "972  0.344295     0.169496   0.843556  0.498691  0.450583  0.391664  0.233060   \n",
      "\n",
      "     Middle_BB  Lower_BB       SMA    Spread  \n",
      "0     0.503378  0.610868  0.503378  0.521171  \n",
      "1     0.503494  0.611048  0.503494  0.519272  \n",
      "2     0.502778  0.609341  0.502778  0.505027  \n",
      "3     0.507827  0.595147  0.507827  0.608344  \n",
      "4     0.514593  0.580479  0.514593  0.636736  \n",
      "..         ...       ...       ...       ...  \n",
      "968   0.283448  0.156893  0.283448  0.360907  \n",
      "969   0.264916  0.179788  0.264916  0.326816  \n",
      "970   0.249568  0.208324  0.249568  0.356289  \n",
      "971   0.235671  0.244589  0.235671  0.361398  \n",
      "972   0.227042  0.266224  0.227042  0.359727  \n",
      "\n",
      "[973 rows x 11 columns]}\n"
     ]
    }
   ],
   "source": [
    "scaled_spreads_with_indicators = {}  # Dictionary to hold scaled data\n",
    "\n",
    "for key, dataframe in spreads_with_indicators.items():\n",
    "    dataframe = dataframe.replace([np.inf], 1)\n",
    "    dataframe = dataframe.replace([-np.inf], 0)\n",
    "\n",
    "    #dataframe = dataframe.dropna()\n",
    "    spreads_with_indicators[key] = dataframe\n",
    "\n",
    "for key, dataframe in spreads_with_indicators.items():\n",
    "\n",
    "    scaled_dataframe = pd.DataFrame()  # DataFrame to hold scaled values for the current key\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))  # Initialize the scaler\n",
    "\n",
    "    for column in dataframe.columns:\n",
    "        # Scale each column and add it to the scaled_dataframe\n",
    "        scaled_values = scaler.fit_transform(dataframe[column].values.reshape(-1, 1))\n",
    "        scaled_dataframe[column] = scaled_values.flatten()  # Flatten the array to 1D and set it as a column\n",
    "\n",
    "    # Add the scaled DataFrame to the dictionary\n",
    "    scaled_spreads_with_indicators[key] = scaled_dataframe\n",
    "\n",
    "# Now scaled_spreads_with_indicators contains the scaled data.\n",
    "print(scaled_spreads_with_indicators)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:34:53.745953Z",
     "start_time": "2024-01-17T12:34:53.426896Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:21:24.191431Z",
     "start_time": "2024-01-17T12:21:24.178410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class RollingWindowDataset(Dataset):\n",
    "    def __init__(self, X, y, device=\"gpu\"):\n",
    "        self.X = torch.tensor(X, dtype=torch.float, device=device)\n",
    "        self.y = torch.tensor(y, dtype=torch.float, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].clone().detach().to(torch.float), self.y[idx].clone().detach().to(torch.float)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T10:48:44.290022Z",
     "start_time": "2024-01-17T10:48:44.287619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, num_layers = layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T10:50:19.472275Z",
     "start_time": "2024-01-17T10:50:19.384528Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = RollingWindowDataset(X_train, y_train, device)\n",
    "test_data = RollingWindowDataset(X_test, y_test, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMModel(input_dim=X_train.shape[2], hidden_dim=22, layer_dim=1, output_dim=y_train.shape[1]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class LSTM_Trainer:\n",
    "    def __init__(self, train_data, test_data, device, optimizer, criterion):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion =  criterion\n",
    "        self.model = LSTMModel(input_dim=1, hidden_dim=22, layer_dim=1, output_dim=1).to(self.device)\n",
    "\n",
    "    def train_lstm(self, config, checkpoint_dir=None):\n",
    "\n",
    "        batch_size = int(round(config[\"batch_size\"]))\n",
    "        epochs = int(round(config[\"epochs\"]))\n",
    "        hidden_dim = int(round(config[\"hidden_dim\"]))\n",
    "        layer_dim = int(round(config[\"layer_dim\"]))\n",
    "        learning_rate = config[\"learning_rate\"]\n",
    "\n",
    "        # Create the model\n",
    "        self.model = LSTMModel(input_dim=1, hidden_dim=hidden_dim, layer_dim=layer_dim, output_dim=1).to(self.device)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Define data loader (you may need to adapt this based on your data format)\n",
    "        train_loader = DataLoader(self.train_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "            running_loss = .0\n",
    "            self.model.train()\n",
    "\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                if isinstance(data, np.ndarray):\n",
    "                    data = torch.from_numpy(data).float()\n",
    "                if isinstance(target, np.ndarray):\n",
    "                    target = torch.from_numpy(target).float()\n",
    "\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                predictions = self.model(data)\n",
    "                loss = self.criterion(predictions, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "\n",
    "            train_loss = running_loss/len(train_loader)\n",
    "            print(train_loss)\n",
    "            train.report({'mse': train_loss})\n",
    "\n",
    "\n",
    "    def Test(self, config, test_data):\n",
    "        batch_size = int(round(config[\"batch_size\"]))\n",
    "        self.test_data = test_data\n",
    "\n",
    "        all_predictions = []\n",
    "        test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        running_loss = .0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                if isinstance(data, np.ndarray):\n",
    "                    data = torch.from_numpy(data).float()\n",
    "                if isinstance(target, np.ndarray):\n",
    "                    target = torch.from_numpy(target).float()\n",
    "\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                preds = self.model(data)\n",
    "                loss = self.criterion(preds,target)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                all_predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "\n",
    "            test_loss = running_loss/len(test_loader)\n",
    "\n",
    "            print(f'test_loss {test_loss}')\n",
    "\n",
    "        all_predictions = np.array(all_predictions)\n",
    "\n",
    "        return all_predictions\n",
    "\n",
    "\n",
    "    def get_current_model(self):\n",
    "        if self.model is not None:\n",
    "            return self.model\n",
    "        else:\n",
    "            raise ValueError(\"Model has not been trained yet.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T10:59:15.739938Z",
     "start_time": "2024-01-17T10:59:15.692107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model_with_config(config, train_data, test_data, device, optimizer, criterion):\n",
    "    trainer = LSTM_Trainer(train_data, test_data, device, optimizer, criterion)\n",
    "    return trainer.train_lstm(config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tuning(train_data, test_data, device, optimizer, criterion):\n",
    "    ray.shutdown()\n",
    "    ray.init(num_cpus=8, num_gpus=1)\n",
    "\n",
    "    # Define hyperparameter configuration\n",
    "    config = {\n",
    "        \"learning_rate\": tune.choice([1e-4, 1e-3, 1e-2]),\n",
    "        \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        \"epochs\": tune.choice([50, 100, 150]),\n",
    "        \"hidden_dim\": tune.choice([22, 35, 50, 75]),\n",
    "        \"layer_dim\": tune.choice([1, 2, 3])\n",
    "    }\n",
    "\n",
    "    # Define scheduler and reporter\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"mse\",\n",
    "        mode=\"min\",\n",
    "        grace_period=15,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    reporter = CLIReporter(metric_columns=[\"mse\", \"training_iteration\"])\n",
    "\n",
    "    # Optuna search algorithm\n",
    "    optuna_search = OptunaSearch(metric=\"mse\", mode=\"min\")\n",
    "\n",
    "    # Partial function for training with LSTM and given data\n",
    "    #train_lstm_with_data = partial(trainer.train_lstm, device=trainer.device)\n",
    "\n",
    "    trainable_with_cpu_gpu = tune.with_resources(lambda config: train_model_with_config(config, train_data, test_data, device, optimizer, criterion), {\"cpu\": 8, \"gpu\": 1})\n",
    "\n",
    "\n",
    "    # Start the tuning process\n",
    "    analysis = tune.run(\n",
    "        trainable_with_cpu_gpu,\n",
    "        # resources_per_trial={\"cpu\": 8, \"gpu\": 1},\n",
    "        config=config,\n",
    "        num_samples=50,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=optuna_search,\n",
    "        progress_reporter=None\n",
    "    )\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_config = analysis.get_best_config(metric=\"mse\", mode=\"min\")\n",
    "    best_mse = analysis.get_best_trial(metric=\"mse\", mode=\"min\").last_result[\"mse\"]\n",
    "\n",
    "    print(\"Best config: \", best_config)\n",
    "    print(f\"Best MSE: {best_mse}\")\n",
    "\n",
    "    return best_config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = []\n",
    "checked_compt = set()\n",
    "\n",
    "\n",
    "for ticker in tqdm(data.columns, desc=\"Processing tickers\"):\n",
    "\n",
    "    train_data = RollingWindowDataset(X_train, y_train, device)\n",
    "    test_data = RollingWindowDataset(X_test, y_test, device)\n",
    "\n",
    "    best_config = tuning(train_data, test_data, device, optimizer, criterion)\n",
    "\n",
    "    trainer = LSTM_Trainer(train_data, test_data, device, optimizer, criterion)\n",
    "    trainer.train_lstm(best_config)\n",
    "    preds = trainer.Test(best_config, test_data)\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_test, preds) * 100\n",
    "    score.append((mape, ticker))\n",
    "\n",
    "    for pair in data.columns:\n",
    "        comp_data_X = company_dict[pair][\"X\"]\n",
    "        comp_data_y = company_dict[pair][\"y\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(comp_data_X, comp_data_y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        test_data = RollingWindowDataset(X_test, y_test, device)\n",
    "\n",
    "        preds = trainer.Test(best_config, test_data)\n",
    "\n",
    "        pair_mape = mean_absolute_percentage_error(y_test, preds) * 100\n",
    "\n",
    "        score.append((mape, ticker , pair, pair_mape))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(951, 22, 11)\n",
      "(951, 11)\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 1/10, Loss: 319.219394\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 2/10, Loss: 264.257516\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 3/10, Loss: 233.387033\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 4/10, Loss: 210.152650\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 5/10, Loss: 191.006456\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 6/10, Loss: 175.112144\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 7/10, Loss: 161.713285\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 8/10, Loss: 150.318541\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 9/10, Loss: 140.438893\n",
      "Pair: ('SWKS', 'QRVO'), Epoch 10/10, Loss: 132.159720\n",
      "(984, 22)\n",
      "(984,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 50\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# Testing\u001B[39;00m\n\u001B[1;32m     49\u001B[0m test_loader \u001B[38;5;241m=\u001B[39m DataLoader(RollingWindowDataset(x_test_scaled, y_test), batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 50\u001B[0m predictions, actuals \u001B[38;5;241m=\u001B[39m \u001B[43mtest_lstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# Calculate and print MAPE\u001B[39;00m\n\u001B[1;32m     53\u001B[0m mape \u001B[38;5;241m=\u001B[39m mean_absolute_percentage_error(actuals[:, \u001B[38;5;241m2\u001B[39m], predictions[:, \u001B[38;5;241m2\u001B[39m])  \u001B[38;5;66;03m# Assuming you want the 3rd column\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[20], line 17\u001B[0m, in \u001B[0;36mtest_lstm\u001B[0;34m(model, test_loader)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data, target \u001B[38;5;129;01min\u001B[39;00m test_loader:\n\u001B[0;32m---> 17\u001B[0m         output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m         predictions\u001B[38;5;241m.\u001B[39mextend(output\u001B[38;5;241m.\u001B[39mnumpy())  \u001B[38;5;66;03m# Store predictions\u001B[39;00m\n\u001B[1;32m     19\u001B[0m         actuals\u001B[38;5;241m.\u001B[39mextend(target\u001B[38;5;241m.\u001B[39mnumpy())  \u001B[38;5;66;03m# Store actual values\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject8/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject8/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[11], line 18\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Initialize cell state\u001B[39;00m\n\u001B[1;32m     16\u001B[0m c0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_dim)\n\u001B[0;32m---> 18\u001B[0m out, (hn, cn) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mh0\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc0\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(out[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :])\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject8/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject8/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject8/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:871\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    868\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m hx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m    869\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFor unbatched 2-D input, hx and cx should \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    870\u001B[0m                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malso be 2-D but got (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-D, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-D) tensors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 871\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[1;32m    872\u001B[0m     hx \u001B[38;5;241m=\u001B[39m (hx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), hx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    873\u001B[0m \u001B[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001B[39;00m\n\u001B[1;32m    874\u001B[0m \u001B[38;5;66;03m# the user believes he/she is passing in.\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "# Example usage with one stock pair\n",
    "pair = selected_pairs[0]  # Example: first pair in the list\n",
    "spread_data = spreads_with_indicators[pair]\n",
    "x, y = rolling_window(spread_data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "#print(x_train.shape)\n",
    "\n",
    "# Train the LSTM model\n",
    "model = train_lstm(pair, x_train, y_train, batch_size, epochs, hidden_dim, num_layers, learning_rate)\n",
    "# Testing function\n",
    "def test_lstm(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            predictions.extend(output.numpy())  # Store predictions\n",
    "            actuals.extend(target.numpy())  # Store actual values\n",
    "    return np.array(predictions), np.array(actuals)\n",
    "\n",
    "# MAPE calculation\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "# Define fixed hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Preprocess and prepare data\n",
    "pair = selected_pairs[0]  # Example: first pair in the list\n",
    "spread_data = data['SWKS'] - data['QRVO']  # Example spread calculation\n",
    "x, y = rolling_window(spread_data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Scaling data (make sure to scale x_train and x_test appropriately)\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "x_test_scaled = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Testing\n",
    "test_loader = DataLoader(RollingWindowDataset(x_test_scaled, y_test), batch_size=batch_size, shuffle=False)\n",
    "predictions, actuals = test_lstm(model, test_loader)\n",
    "\n",
    "# Calculate and print MAPE\n",
    "mape = mean_absolute_percentage_error(actuals[:, 2], predictions[:, 2])  # Assuming you want the 3rd column\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T11:01:39.771790Z",
     "start_time": "2024-01-17T11:01:32.076780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate and print MAPE\n",
    "mape = mean_absolute_percentage_error(actuals[:, 2], predictions[:, 2])  # Assuming you want the 3rd column\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Visualization of the 3rd column of actuals vs predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actuals[:, 2], label='Actual Values (3rd Column)', color='blue')  # Plotting the 3rd column of actuals\n",
    "plt.plot(predictions[:, 2], label='Predicted Values (3rd Column)', color='red')  # Plotting the 3rd column of predictions\n",
    "plt.title('LSTM Model Predictions vs Actual Values (3rd Column)')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "selected_data['1. spread'] = scaler.fit_transform(selected_data['1. spread'].values.reshape(-1,1))\n",
    "scaled_data = selected_data\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=selected_data.columns)\n",
    "\n",
    "\n",
    "scaled_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(stock, look_back):\n",
    "    data_raw = stock.values # convert to numpy array\n",
    "    data = []\n",
    "\n",
    "    # create all possible sequences of length look_back\n",
    "    for index in range(len(data_raw) - look_back):\n",
    "        data.append(data_raw[index: index + look_back])\n",
    "\n",
    "    data = np.array(data);\n",
    "    test_set_size = int(np.round(0.2*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (test_set_size);\n",
    "\n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "\n",
    "    x_test = data[train_set_size:,:-1]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "look_back = 60 # choose sequence length\n",
    "x_train, y_train, x_test, y_test = load_data(scaled_data, look_back)\n",
    "print('x_train.shape = ',x_train.shape)\n",
    "print('y_train.shape = ',y_train.shape)\n",
    "print('x_test.shape = ',x_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make training and test sets in torch\n",
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.size(),x_train.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RollingWindowDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float)\n",
    "# Define LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "# Parameters\n",
    "look_back = 60\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "num_epochs = 100\n",
    "loss_fn = torch.nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RollingWindowDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build model\n",
    "#####################\n",
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 32, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "\n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train model\n",
    "#####################\n",
    "num_epochs = 100\n",
    "hist = np.zeros(num_epochs)\n",
    "\n",
    "# Number of steps to unroll\n",
    "seq_dim =look_back-1\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    #model.hidden = model.init_hidden()\n",
    "\n",
    "    # Forward pass\n",
    "    y_train_pred = model(x_train)\n",
    "\n",
    "    loss = loss_fn(y_train_pred, y_train)\n",
    "    if t % 10 == 0 and t !=0:\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.shape(y_train_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_test_pred = model(x_test)\n",
    "\n",
    "# invert predictions\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
    "y_train = scaler.inverse_transform(y_train.detach().numpy())\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(y_test.detach().numpy())\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "figure, axes = plt.subplots(figsize=(15, 6))\n",
    "axes.xaxis_date()\n",
    "\n",
    "axes.plot(scaled_data[len(scaled_data)-len(y_test):].index, y_test, color = 'red', label = 'Actual Spread')\n",
    "axes.plot(scaled_data[len(scaled_data)-len(y_test):].index, y_test_pred, color = 'blue', label = 'Predicted Spread')\n",
    "#axes.xticks(np.arange(0,394,50))\n",
    "plt.title('Spread Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Spread Price')\n",
    "plt.legend()\n",
    "plt.savefig('spread.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
